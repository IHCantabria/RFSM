{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from netCDF4 import Dataset, date2num\n",
    "import glob\n",
    "import scipy.io\n",
    "import tqdm\n",
    "import xarray as xr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pomegranate import *\n",
    "\n",
    "from scipy.stats import genextreme as gev\n",
    "from scipy.stats import gumbel_l as gumbel\n",
    "from scipy.stats import gamma as gamma\n",
    "from scipy.stats import expon as exp\n",
    "from scipy.stats import lognorm as logn\n",
    "from scipy.stats import gumbel_r as gumbel_r\n",
    "from scipy.stats import powerlaw as powerlaw\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import statsmodels as sm\n",
    "import statsmodels.api as sma\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import warnings\n",
    "from pyproj import Proj, transform\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from dateutil.parser import parse\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(); sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pdf(dist, params, size=10000):\n",
    "    \"\"\"Generate distributions's Probability Distribution Function \"\"\"\n",
    "\n",
    "    # Separate parts of parameters\n",
    "    arg = params[:-2]\n",
    "    loc = params[-2]\n",
    "    scale = params[-1]\n",
    "\n",
    "    # Get sane start and end points of distribution\n",
    "    start = dist.ppf(0.01, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.01, loc=loc, scale=scale)\n",
    "    end = dist.ppf(0.99, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.99, loc=loc, scale=scale)\n",
    "\n",
    "    # Build PDF and turn into pandas Series\n",
    "    x = np.linspace(start, end, size)\n",
    "    y = dist.pdf(x, loc=loc, scale=scale, *arg)\n",
    "    pdf = pd.Series(y, x)\n",
    "\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ajuste_GEV_KMA_Frechet(data, plot=False):\n",
    "    #Ajuste Gumbel\n",
    "    func=getattr(st,'genextreme')\n",
    "    paramt = func.fit(data,fc=0.0000000001)\n",
    "    nlogL = np.log(func.pdf(data,*paramt)).sum()\n",
    "    parmhatgev = func.fit(data)\n",
    "    nlogLGev = np.log(func.pdf(data,*parmhatgev)).sum()\n",
    "    \n",
    "    if -parmhatgev[0]>0:\n",
    "        isgev = np.sum((np.abs(nlogLGev)-np.abs(nlogL))>=1.92)\n",
    "        if  isgev==1:\n",
    "                paramGev= parmhatgev\n",
    "        else:\n",
    "             paramGev = paramt\n",
    "    else:\n",
    "        paramGev= parmhatgev\n",
    "\n",
    "    if plot == True:\n",
    "        fig, ax=plt.subplots(2, 2, figsize=(12, 8))\n",
    "        data.plot(kind='hist', bins=50, density =True, alpha=0.5, color='red',ax=ax[0,0])\n",
    "        dataYLim = ax[0,0].get_ylim()\n",
    "        distribution=getattr(st,'genextreme')\n",
    "        best_distribution = distribution\n",
    "        best_dist = getattr(st,'genextreme')\n",
    "        best_fit_params = paramGev\n",
    "        best_fit_name='genextreme'\n",
    "\n",
    "        #----------------------------------------------------------------------------------- \n",
    "        pdf = make_pdf(best_dist, best_fit_params)\n",
    "\n",
    "        pdf.plot(lw=2, label='PDF', legend=True, ax=ax[0,0])\n",
    "        data.plot(kind='hist', bins=50, density=True, alpha=0.5, label='Data', legend=True, ax=ax[0,0])\n",
    "\n",
    "        param_names = (best_dist.shapes + ', loc, scale').split(', ') if best_dist.shapes else ['loc', 'scale']\n",
    "        param_str = ', '.join(['{}={:0.2f}'.format(k,v) for k,v in zip(param_names, best_fit_params)])\n",
    "        dist_str = '{}({})'.format(best_fit_name, param_str)\n",
    "\n",
    "        ax[0,0].set_title(u'Best probability density function \\n' + dist_str)\n",
    "        ax[0,0].set_xlabel(u'Data')\n",
    "        ax[0,0].set_ylabel('Frequency')\n",
    "        ax[0,0].set_ylim(dataYLim)\n",
    "        #-----------------------------------------------------------------------------------     \n",
    "        data=data.values.flatten()\n",
    "        PQmax_1 = best_dist.cdf(data.astype(float),*best_fit_params);\n",
    "        Qemp = np.sort(data);\n",
    "        kk = np.arange(1,len(data)+1);\n",
    "        prob = kk/(len(data));\n",
    "        Qlogn  = best_dist.ppf(prob,*best_fit_params);\n",
    "        ax[0,1].plot(Qemp,Qlogn,'.k')\n",
    "        ax[0,1].plot(np.arange(min(data),max(data)),np.arange(min(data),max(data)),'-b')\n",
    "        ax[0,1].set_title('Q-Q Plot \\n' + dist_str)\n",
    "        ax[0,1].set_xlabel(u'Empirical')\n",
    "        ax[0,1].set_ylabel('Model')\n",
    "        #-----------------------------------------------------------------------------------     \n",
    "        ecdf=ECDF(data)\n",
    "        x = np.linspace(min(data),max(data),200)\n",
    "        y = best_dist.cdf(x, *best_fit_params)\n",
    "        ax[1,0].plot(x, y)\n",
    "        ax[1,0].scatter(data.astype(float),ecdf(data))\n",
    "        ax[1,0].set_title('Best Cumulative density function \\n' + dist_str)\n",
    "        ax[1,0].set_xlabel(u'Data')\n",
    "        ax[1,0].set_ylabel('Prob')\n",
    "        #-----------------------------------------------------------------------------------    \n",
    "        x_r=np.arange(0.01,1000)\n",
    "        prob_t=(1-1/x_r)\n",
    "        y_r=best_dist.ppf(prob_t,*best_fit_params)\n",
    "        ax[1,1].plot(x_r,y_r,'-b')\n",
    "\n",
    "        ecdf=ECDF(data)\n",
    "        t_r=1/(1-ecdf(data))\n",
    "        ax[1,1].plot(t_r,data,'.k')\n",
    "        ax[1,1].set_xscale(\"log\")\n",
    "        ax[1,1].set_xlabel(u'Return Periods')\n",
    "        ax[1,1].set_ylabel('Return Values')\n",
    "        ax[1,1].set_title('Return Values Plot \\n' + dist_str)\n",
    "\n",
    "        print(best_fit_params)\n",
    "        fig.tight_layout()  \n",
    "    func=getattr(st,'genextreme')\n",
    "    \n",
    "    PeriodoRetorno=[2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100,200,500,1000]\n",
    "    TWL = pd.DataFrame(index=PeriodoRetorno,columns=['TWL'])\n",
    "    for i in PeriodoRetorno:\n",
    "        TWL.loc[i] = func.ppf((1-1/i),*paramGev)\n",
    "        \n",
    "    return TWL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matDatenum2PYDatetime(datenumVec,unitTime = 'D'):\n",
    "    datetimeVec = pd.to_datetime(datenumVec-719529, unit=unitTime,errors='coerce')\n",
    "    datetimeNum = datenumVec-719529\n",
    "    return datetimeVec,datetimeNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_netcf_Dinamicas_DOW(path_files,path_output,model,scenario):\n",
    "    directory = list() \n",
    "    for file in os.listdir(path_files):\n",
    "        if file.startswith(\"Punto\"):\n",
    "            directory.append(file)\n",
    "    names_point = list()\n",
    "    lon = list()\n",
    "    lat = list()\n",
    "    for d, dd in enumerate(directory):\n",
    "        names_point.append(dd[:-19])\n",
    "        lon.append(float(dd[-17:-10]))\n",
    "        lat.append(float(dd[-8:-1]))\n",
    "        \n",
    "    for i,ii in enumerate(tqdm.tqdm(directory)):\n",
    "        if i ==0:\n",
    "            mat    = scipy.io.loadmat(path_files+directory[i]+'/'+directory[i]+'_'+model+'_'+scenario+'.mat')\n",
    "            time   = mat['time'].flatten()\n",
    "            hs_o   = mat['hs'].reshape(1,-1)\n",
    "            tps_o  = mat['tps'].reshape(1,-1)\n",
    "            dir_o  = mat['dir'].reshape(1,-1)\n",
    "            zeta_o = mat['zeta'].reshape(1,-1)\n",
    "            tm02_o = mat['tm02'].reshape(1,-1)\n",
    "        else:\n",
    "            mat = scipy.io.loadmat(path_files+directory[i]+'/'+directory[i]+'_'+model+'_'+scenario+'.mat')\n",
    "            hs_o   = np.concatenate((hs_o, mat['hs'].reshape(1,-1)), axis=0)\n",
    "            tps_o  = np.concatenate((tps_o, mat['tps'].reshape(1,-1)), axis=0)\n",
    "            dir_o  = np.concatenate((dir_o, mat['dir'].reshape(1,-1)), axis=0)\n",
    "            zeta_o = np.concatenate((zeta_o, mat['zeta'].reshape(1,-1)), axis=0)\n",
    "            tm02_o = np.concatenate((tm02_o, mat['tm02'].reshape(1,-1)), axis=0)\n",
    "        \n",
    "    time_py = matDatenum2PYDatetime(time,unitTime = 'D')[0]\n",
    "    \n",
    "    nc = Dataset(path_output+'PtosObjtvo_DIN_'+model+'_'+scenario+'.nc', 'w', format='NETCDF4')\n",
    "    # Global Attributes \n",
    "    nc.description= 'Contiene las din√°micas del modelo '+model+' en el escenario '+scenario  \n",
    "    # nc dimensions\n",
    "    nc.createDimension('lon',  len(lon))\n",
    "    nc.createDimension('lat',  len(lat))\n",
    "    nc.createDimension('time',len(time))\n",
    "    #nc.createDimension('point',len(names_point))\n",
    "    # crear variables\n",
    "    xx_nc=nc.createVariable('lon','float32', ('lon'))\n",
    "    yy_nc=nc.createVariable('lat','float32', ('lat'))\n",
    "    time_nc=nc.createVariable('time','float32',('time'))\n",
    "    #point_nc = nc.createVariable('point','int',('point'))\n",
    "    hs_nc=nc.createVariable('hs','float32', ('time','lon'))\n",
    "    tps_nc=nc.createVariable('tps','float32', ('time','lon'))\n",
    "    dir_nc=nc.createVariable('dir','float32', ('time','lon'))\n",
    "    zeta_nc=nc.createVariable('zeta','float32', ('time','lon'))\n",
    "    tm02_nc=nc.createVariable('tm02','float32', ('time','lon'))\n",
    "    #units\n",
    "    xx_nc.units = 'degrees_east'\n",
    "    yy_nc.units = 'degrees_north'\n",
    "    time_nc.units='days since '+str(time_py[0].year)+'-01-01'\n",
    "    hs_nc.units='m'\n",
    "    tps_nc.units='s'\n",
    "    dir_nc.units='¬∫'\n",
    "    zeta_nc.units='¬∫'\n",
    "    tm02_nc.units='s'\n",
    "    #long_name\n",
    "    xx_nc.long_name = 'longitude coordinate'\n",
    "    yy_nc.long_name = 'latitud coordinate'\n",
    "    time_nc.long_name='dias del a√±o'\n",
    "    hs_nc.long_name='Altura de ola'\n",
    "    tps_nc.long_name='Per√≠odo de pico suavizado'\n",
    "    dir_nc.long_name='Direcci√≥n'\n",
    "    zeta_nc.long_name='Marea meteorol√≥gica'\n",
    "    tm02_nc.long_name='Periodo medio'\n",
    "    # calendar\n",
    "    time_nc.calendar = 'standard'\n",
    "    # rellenar variables\n",
    "    #point_nc[:]=np.arange(1,len(names_point)+1)\n",
    "    xx_nc[:]=lon\n",
    "    yy_nc[:]=lat\n",
    "    time_nc[:]=date2num(time_py.to_pydatetime(), units='days since '+str(time_py[0].year)+'-01-01', calendar='standard')\n",
    "    hs_nc[:]=hs_o[:,:].T\n",
    "    tps_nc[:]=tps_o[:,:].T\n",
    "    dir_nc[:]=dir_o[:,:].T\n",
    "    zeta_nc[:] = zeta_o[:,:].T\n",
    "    tm02_nc[:]=tm02_o[:,:].T\n",
    "    nc.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_netcf_MareaAst(path_files,path_output):\n",
    "    directory = list() \n",
    "    for file in os.listdir(path_files):\n",
    "        if file.startswith(\"Punto\"):\n",
    "            directory.append(file)\n",
    "    names_point = list()\n",
    "    lon = list()\n",
    "    lat = list()\n",
    "    for d, dd in enumerate(directory):\n",
    "        names_point.append(dd[:-23])\n",
    "        lon.append(float(dd[-21:-14]))\n",
    "        lat.append(float(dd[-12:-5]))\n",
    "        \n",
    "    for i,ii in enumerate(tqdm.tqdm(directory)):\n",
    "        if i ==0:\n",
    "            mat    = scipy.io.loadmat(path_files+directory[i])\n",
    "            time   = mat['time'].flatten()\n",
    "            lon_tide_o = mat['lon_tide']\n",
    "            lat_tide_o = mat['lat_tide']\n",
    "            tide_o  = mat['tide'].reshape(1,-1)\n",
    "            u_o  = mat['u'].reshape(1,-1)\n",
    "            v_o  = mat['v'].reshape(1,-1)\n",
    "        else:\n",
    "            mat    = scipy.io.loadmat(path_files+directory[i])\n",
    "            tide_o  =  np.concatenate((tide_o,mat['tide'].reshape(1,-1)),axis=0)\n",
    "            lon_tide_o = np.concatenate((lon_tide_o,mat['lon_tide']),axis=0)\n",
    "            lat_tide_o = np.concatenate((lat_tide_o,mat['lat_tide']),axis=0)\n",
    "            u_o  = np.concatenate((u_o,mat['u'].reshape(1,-1)),axis=0)\n",
    "            v_o  = np.concatenate((v_o,mat['v'].reshape(1,-1)),axis=0)\n",
    "        \n",
    "    time_py = matDatenum2PYDatetime(time,unitTime = 'D')[0]\n",
    "    nc = Dataset(path_output+'PtosObjtvo_MAT.nc', 'w', format='NETCDF4')\n",
    "    # Global Attributes \n",
    "    nc.description= 'Contiene la variable Marea Astron√≥mica' \n",
    "    # nc dimensions\n",
    "    nc.createDimension('lon',  len(lon))\n",
    "    nc.createDimension('lat',  len(lat))\n",
    "    nc.createDimension('time',len(time))\n",
    "    #nc.createDimension('point',len(names_point))\n",
    "    # crear variables\n",
    "    xx_nc=nc.createVariable('lon','float32', ('lon'))\n",
    "    yy_nc=nc.createVariable('lat','float32', ('lat'))\n",
    "    time_nc=nc.createVariable('time','float32',('time'))\n",
    "    lon_tide_nc = nc.createVariable('lon_tide','float32', ('lon'))\n",
    "    lat_tide_nc = nc.createVariable('lat_tide','float32', ('lat'))\n",
    "    #point_nc = nc.createVariable('point','int',('point'))\n",
    "    tide_nc=nc.createVariable('tide','float32', ('time','lon'))\n",
    "    u_nc=nc.createVariable('u','float32', ('time','lon'))\n",
    "    v_nc=nc.createVariable('v','float32', ('time','lon'))\n",
    "    #units\n",
    "    xx_nc.units = 'degrees_east'\n",
    "    yy_nc.units = 'degrees_north'\n",
    "    time_nc.units='days since '+str(time_py[0].year)+'-01-01'\n",
    "    lon_tide_nc.units = 'degrees_east'\n",
    "    lat_tide_nc.units = 'degrees_north'\n",
    "    tide_nc.units='m'\n",
    "    u_nc.units='m'\n",
    "    v_nc.units='m'\n",
    "    #long_name\n",
    "    xx_nc.long_name = 'longitude coordinate'\n",
    "    yy_nc.long_name = 'latitud coordinate'\n",
    "    lon_tide_nc.long_name = 'longitude coordinate tide'\n",
    "    lat_tide_nc.long_name = 'latitud coordinate tide'\n",
    "    time_nc.long_name='dias del a√±o'\n",
    "    tide_nc.long_name='Altura'\n",
    "    u_nc.long_name='Direcci√≥n horizontal'\n",
    "    v_nc.long_name='Direcci√≥n vertical'\n",
    "    \n",
    "    # calendar\n",
    "    time_nc.calendar = 'standard'\n",
    "    # rellenar variables\n",
    "    #point_nc[:]=np.arange(1,len(names_point)+1)\n",
    "    xx_nc[:]=lon\n",
    "    yy_nc[:]=lat\n",
    "    lon_tide_nc[:] = lon_tide_o\n",
    "    lat_tide_nc[:] = lat_tide_o\n",
    "    time_nc[:]=date2num(time_py.to_pydatetime(), units='days since '+str(time_py[0].year)+'-01-01', calendar='standard')\n",
    "    tide_nc[:]=tide_o[:,:].T\n",
    "    u_nc[:]=u_o[:,:].T\n",
    "    v_nc[:]=v_o[:,:].T\n",
    "    nc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_netcf_Dinamicas_SLR(path_files,path_output):\n",
    "    directory = list() \n",
    "    for file in os.listdir(path_files):\n",
    "        if file.startswith(\"Punto\"):\n",
    "            directory.append(file)\n",
    "    names_point = list()\n",
    "    lon = list()\n",
    "    lat = list()\n",
    "    for d, dd in enumerate(directory):\n",
    "        names_point.append(dd[:-27])\n",
    "        lon.append(float(dd[-25:-18]))\n",
    "        lat.append(float(dd[-16:-9]))\n",
    "        \n",
    "    for i,ii in enumerate(tqdm.tqdm(directory)):\n",
    "        if i ==0:\n",
    "            mat    = scipy.io.loadmat(path_files+directory[i])\n",
    "            time   = mat['time'].flatten()\n",
    "            m_ensemble45_o  = mat['m_ensemble45'].reshape(1,-1)\n",
    "            m_ensemble85_o  = mat['m_ensemble85'].reshape(1,-1)\n",
    "            P5_45_o  = mat['P5_45'].reshape(1,-1)\n",
    "            P5_85_o  = mat['P5_85'].reshape(1,-1)\n",
    "            P95_45_o = mat['P95_45'].reshape(1,-1)\n",
    "            P95_85_o = mat['P95_85'].reshape(1,-1)\n",
    "        else:\n",
    "            mat = scipy.io.loadmat(path_files+directory[i])\n",
    "            m_ensemble45_o   = np.concatenate((m_ensemble45_o, mat['m_ensemble45'].reshape(1,-1)), axis=0)\n",
    "            m_ensemble85_o  = np.concatenate((m_ensemble85_o, mat['m_ensemble85'].reshape(1,-1)), axis=0)\n",
    "            P5_45_o  = np.concatenate((P5_45_o, mat['P5_45'].reshape(1,-1)), axis=0)\n",
    "            P5_85_o  = np.concatenate((P5_85_o, mat['P5_85'].reshape(1,-1)), axis=0)\n",
    "            P95_45_o = np.concatenate((P95_45_o, mat['P95_45'].reshape(1,-1)), axis=0)\n",
    "            P95_85_o = np.concatenate((P95_85_o, mat['P95_85'].reshape(1,-1)), axis=0)\n",
    "        \n",
    "    time_py = matDatenum2PYDatetime(time,unitTime = 'D')[0]\n",
    "    \n",
    "    nc = Dataset(path_output+'PtosObjtvo_MSL.nc', 'w', format='NETCDF4')\n",
    "    # Global Attributes \n",
    "    nc.description= 'Contiene la variable SLR' \n",
    "    # nc dimensions\n",
    "    nc.createDimension('lon',  len(lon))\n",
    "    nc.createDimension('lat',  len(lat))\n",
    "    nc.createDimension('time',len(time))\n",
    "    #nc.createDimension('point',len(names_point))\n",
    "    # crear variables\n",
    "    xx_nc=nc.createVariable('lon','float32', ('lon'))\n",
    "    yy_nc=nc.createVariable('lat','float32', ('lat'))\n",
    "    time_nc=nc.createVariable('time','float32',('time'))\n",
    "    #point_nc = nc.createVariable('point','int',('point'))\n",
    "    m_ensemble45_nc=nc.createVariable('m_ensemble45','float32', ('time','lon'))\n",
    "    m_ensemble85_nc=nc.createVariable('m_ensemble85','float32', ('time','lon'))\n",
    "    P5_45_nc=nc.createVariable('P5_45','float32', ('time','lon'))\n",
    "    P5_85_nc=nc.createVariable('P5_85','float32', ('time','lon'))\n",
    "    P95_45_nc=nc.createVariable('P95_45','float32', ('time','lon'))\n",
    "    P95_85_nc=nc.createVariable('P95_85','float32', ('time','lon'))\n",
    "    #units\n",
    "    xx_nc.units = 'degrees_east'\n",
    "    yy_nc.units = 'degrees_north'\n",
    "    time_nc.units='days since '+str(time_py[0].year)+'-01-01'\n",
    "    m_ensemble45_nc.units='m'\n",
    "    m_ensemble85_nc.units='s'\n",
    "    P5_45_nc.units='¬∫'\n",
    "    P5_85_nc.units='¬∫'\n",
    "    P95_45_nc.units='¬∫'\n",
    "    P95_85_nc.units='l'\n",
    "    #long_name\n",
    "    xx_nc.long_name = 'longitude coordinate'\n",
    "    yy_nc.long_name = 'latitud coordinate'\n",
    "    time_nc.long_name='dias del a√±o'\n",
    "    m_ensemble45_nc.long_name='Ensemble RCP 45'\n",
    "    m_ensemble85_nc.long_name='Ensemble RCP 85'\n",
    "    P5_45_nc.long_name='Percentil 5% para el RCP 45'\n",
    "    P5_85_nc.long_name='Percentil 5% para el RCP 85'\n",
    "    P95_45_nc.long_name='Percentil 95% para el RCP 45'\n",
    "    P95_85_nc.long_name='Percentil 95% para el RCP 85'\n",
    "    # calendar\n",
    "    time_nc.calendar = 'standard'\n",
    "    # rellenar variables\n",
    "    #point_nc[:]=np.arange(1,len(names_point)+1)\n",
    "    xx_nc[:]=lon\n",
    "    yy_nc[:]=lat\n",
    "    time_nc[:]=date2num(time_py.to_pydatetime(), units='days since '+str(time_py[0].year)+'-01-01', calendar='standard')\n",
    "    m_ensemble45_nc[:]=m_ensemble45_o[:,:].T\n",
    "    m_ensemble85_nc[:]=m_ensemble85_o[:,:].T\n",
    "    P5_45_nc[:]=P5_45_o[:,:].T\n",
    "    P5_85_nc[:]=P5_85_o[:,:].T\n",
    "    P95_45_nc[:] = P95_45_o[:,:].T\n",
    "    P95_85_nc[:]=P95_85_o[:,:].T\n",
    "    nc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_fun (Tp,Hs,idplaya,slope,CStock):\n",
    "            L0=9.81/(2.*np.pi)*(Tp**2);\n",
    "            if idplaya == 1:\n",
    "                beta = slope; #% 1/30;\n",
    "                Irb=beta/np.sqrt(Hs/L0);#% Batjes,1974\n",
    "                # Stockdon,H.F. 2006; Runup2%\n",
    "                Stockdon_setup=CStock*beta*np.sqrt(Hs*L0);\n",
    "                #        s = find(Irb < 0.3);\n",
    "                #         Stockdon_setup(s)=0.016.*sqrt(Hs(s).*L0(s));\n",
    "                #Stockdon_setup=0.04.*sqrt(Hs.*L0);\n",
    "            else:\n",
    "                Stockdon_setup=0.08*np.sqrt(Hs*L0);\n",
    "            return Stockdon_setup\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_files_extrems_CC(path_inputs_dinamicas,model,path_project,table_point_carac,refNMMA,fin_year_period,cod_epsg):\n",
    "    \"\"\" La siguiente funci√≥n nos permite generar los ficheros de TWL para cada escenario de cambio clim√°tico.\n",
    "        A continuaci√≥n se explican cada uno de los par√°metros de entrada necesarios y los outputs generados\n",
    "        \n",
    "        Par√°metros:\n",
    "        ---------------------\n",
    "        path_inputs_dinamicas   : string. path donde se encuentran los netcdf de las din√°micas para cada uno de los puntos de estudio\n",
    "        model                   : string. Modelo de cambio clim√°tico que se desea analizar\n",
    "        path_project            : string. path donde se encuentra el proyecto de RFSM\n",
    "        table_point_carac       : pandas dataframe. Dataframe con las coordenadas y caracter√≠sticas de los puntos donde se van a asignar las din√°micas\n",
    "        refNMMA                 : float. Referencia nivel medio del mar\n",
    "        fin_year_period         : array. Fecha de fin de cada uno de los per√≠odos que se desean analizar\n",
    "        cod_epsg                : int. C√≥digo epsg del sistema de coordenadas utilizado en las coordendas de los puntos de estudio\n",
    "        \n",
    "        Salidas:\n",
    "        ---------------------\n",
    "        Ficheros csv para cada uno de modelos, escenarios y periodos.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    PtosObjtvo_DOW_his_nc = xr.open_dataset(path_inputs_dinamicas+'PtosObjtvo_DIN_'+model+'_his.nc')\n",
    "    PtosObjtvo_DOW_his_nc = PtosObjtvo_DOW_his_nc.sortby('lon')\n",
    "    PtosObjtvo_DOW_rcp45_nc = xr.open_dataset(path_inputs_dinamicas+'PtosObjtvo_DIN_'+model+'_rcp45.nc')\n",
    "    PtosObjtvo_DOW_rcp45_nc = PtosObjtvo_DOW_rcp45_nc.sortby('lon')\n",
    "    PtosObjtvo_DOW_rcp85_nc = xr.open_dataset(path_inputs_dinamicas+'PtosObjtvo_DIN_'+model+'_rcp85.nc')\n",
    "    PtosObjtvo_DOW_rcp85_nc = PtosObjtvo_DOW_rcp85_nc.sortby('lon')\n",
    "    PtosObjtvo_MSL_nc = xr.open_dataset(path_inputs_dinamicas+'PtosObjtvo_MSL.nc')\n",
    "    PtosObjtvo_MSL_nc = PtosObjtvo_MSL_nc.sortby('lon')\n",
    "    PtosObjtvo_MAT_nc = xr.open_dataset(path_inputs_dinamicas+'PtosObjtvo_MAT.nc')\n",
    "    PtosObjtvo_MAT_nc = PtosObjtvo_MAT_nc.sortby('lon')\n",
    "\n",
    "    PeriodoRetorno=[2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100,200,500,1000]\n",
    "    string_PR = [str(int) for int in PeriodoRetorno]\n",
    "    if os.path.exists(path_project+'sites/CC/')==False:\n",
    "        os.mkdir(path_project+'sites/CC/')\n",
    "    \n",
    "    for t in range(len(fin_year_period)):\n",
    "        print('Calculando TWL del per√≠odo hasta '+str(fin_year_period[t]))\n",
    "        TWL_extrem_rcp_45_tab = pd.DataFrame(index=table_point_carac.index,columns=string_PR+['MSLR','SLR_5','SLR_95'])\n",
    "        TWL_extrem_rcp_85_tab = pd.DataFrame(index=table_point_carac.index,columns=string_PR+['MSLR','SLR_5','SLR_95'])\n",
    "        \n",
    "        TWL_extrem_hist_tab = pd.DataFrame(index=table_point_carac.index,columns=string_PR+['MSLR','SLR_5','SLR_95'])\n",
    "        TWL_extrem_hist_tab.loc[:,['MSLR','SLR_5','SLR_95']] = 0\n",
    "   \n",
    "        for i in tqdm.tqdm(range(len(table_point_carac))):\n",
    "\n",
    "            x_0 = table_point_carac.iloc[i,0]\n",
    "            y_0 = table_point_carac.iloc[i,1]\n",
    "\n",
    "            inProj = Proj(init='epsg:'+str(cod_epsg))\n",
    "            outProj = Proj(init='epsg:4326')\n",
    "\n",
    "            x,y = transform(inProj,outProj,x_0,y_0)\n",
    "\n",
    "\n",
    "            idoleaje = table_point_carac.iloc[i,2]\n",
    "            idmarea = table_point_carac.iloc[i,3]\n",
    "            idplaya = table_point_carac.iloc[i,3]\n",
    "            slope = table_point_carac.iloc[i,4]\n",
    "            CStock = table_point_carac.iloc[i,5]\n",
    "\n",
    "            point_selec_his = PtosObjtvo_DOW_his_nc.point.data[np.sqrt((x-PtosObjtvo_DOW_his_nc.lon.data)**2+(y-PtosObjtvo_DOW_his_nc.lat.data)**2).argmin()]\n",
    "            \n",
    "            point_selec_rcp_45 = PtosObjtvo_DOW_rcp45_nc.point.data[np.sqrt((x-PtosObjtvo_DOW_rcp45_nc.lon.data)**2+(y-PtosObjtvo_DOW_rcp45_nc.lat.data)**2).argmin()]\n",
    "            \n",
    "            point_selec_rcp_85 = PtosObjtvo_DOW_rcp85_nc.point.data[np.sqrt((x-PtosObjtvo_DOW_rcp85_nc.lon.data)**2+(y-PtosObjtvo_DOW_rcp85_nc.lat.data)**2).argmin()]\n",
    "            \n",
    "            point_selec_MSL = PtosObjtvo_MSL_nc.point.data[np.sqrt((x-PtosObjtvo_MSL_nc.lon.data)**2+(y-PtosObjtvo_MSL_nc.lat.data)**2).argmin()]\n",
    "            \n",
    "            point_selec_MAT = PtosObjtvo_MAT_nc.point.data[np.sqrt((x-PtosObjtvo_MAT_nc.lon.data)**2+(y-PtosObjtvo_MAT_nc.lat.data)**2).argmin()]\n",
    "            \n",
    "            \n",
    "            \n",
    "            Hs_his = PtosObjtvo_DOW_his_nc.sel(point = point_selec_his)['hs'].to_dataframe()\n",
    "            Hs_his.index = Hs_his.index.round('H')\n",
    "            try:\n",
    "                Hs_his[Hs_his.hs<0]=0.001\n",
    "            except:\n",
    "                Hs_his = Hs_his\n",
    "\n",
    "            Tp_his = PtosObjtvo_DOW_his_nc.sel(point = point_selec_his)['tps'].to_dataframe()\n",
    "            Tp_his.index = Tp_his.index.round('H')\n",
    "            try:\n",
    "                Tp_his[Tp_his.tps<=0]=np.mean(Tp_his[Tp_his>0],axis=0)\n",
    "            except:\n",
    "                Tp_his = Tp_his\n",
    "\n",
    "            SS_his = PtosObjtvo_DOW_his_nc.sel(point = point_selec_his)['zeta'].to_dataframe()\n",
    "            SS_his.index = SS_his.index.round('H')\n",
    "\n",
    "            Hs_rcp_45 = PtosObjtvo_DOW_rcp45_nc.sel(point = point_selec_rcp_45)['hs'].to_dataframe()\n",
    "            Hs_rcp_45.index = Hs_rcp_45.index.round('H')\n",
    "            try:\n",
    "                Hs_rcp_45[Hs_rcp_45.hs<0]=0.001\n",
    "            except:\n",
    "                Hs_rcp_45 = Hs_rcp_45\n",
    "\n",
    "            Tp_rcp_45 = PtosObjtvo_DOW_rcp45_nc.sel(point = point_selec_rcp_45)['tps'].to_dataframe()\n",
    "            Tp_rcp_45.index = Tp_rcp_45.index.round('H')\n",
    "            try:\n",
    "                Tp_rcp_45[Tp_rcp_45.tps<=0]=np.mean(Tp_rcp_45[Tp_rcp_45>0],axis=0)\n",
    "            except:\n",
    "                Tp_rcp_45 = Tp_rcp_45\n",
    "\n",
    "            SS_rcp45 = PtosObjtvo_DOW_rcp45_nc.sel(point = point_selec_rcp_45)['zeta'].to_dataframe()\n",
    "            SS_rcp45.index = SS_rcp45.index.round('H')\n",
    "\n",
    "            Hs_rcp_85 = PtosObjtvo_DOW_rcp85_nc.sel(point = point_selec_rcp_85)['hs'].to_dataframe()\n",
    "            Hs_rcp_85.index = Hs_rcp_85.index.round('H')\n",
    "            try:\n",
    "                Hs_rcp_85[Hs_rcp_85.hs<0]=0.001\n",
    "            except:\n",
    "                Hs_rcp_85 = Hs_rcp_85\n",
    "\n",
    "            Tp_rcp_85 = PtosObjtvo_DOW_rcp85_nc.sel(point = point_selec_rcp_85)['tps'].to_dataframe()\n",
    "            Tp_rcp_85.index = Tp_rcp_85.index.round('H')\n",
    "            try:\n",
    "                Tp_rcp_85[Tp_rcp_85.tps<=0]=np.mean(Tp_rcp_85[Tp_rcp_85>0],axis=0)\n",
    "            except:\n",
    "                Tp_rcp_85 = Tp_rcp_85\n",
    "\n",
    "            SS_rcp85 = PtosObjtvo_DOW_rcp85_nc.sel(point = point_selec_rcp_85)['zeta'].to_dataframe()\n",
    "            SS_rcp85.index = SS_rcp85.index.round('H')\n",
    "\n",
    "\n",
    "            MSLR_rcp45 = PtosObjtvo_MSL_nc.sel(point = point_selec_MSL)['m_ensemble45'].to_dataframe()\n",
    "            MSLR_rcp45.index = MSLR_rcp45.index.round('H')\n",
    "\n",
    "            SLR_95_rcp45   = PtosObjtvo_MSL_nc.sel(point = point_selec_MSL)['P95_45'].to_dataframe()\n",
    "            SLR_95_rcp45.index = SLR_95_rcp45.index.round('H')\n",
    "\n",
    "            SLR_5_rcp45   = PtosObjtvo_MSL_nc.sel(point = point_selec_MSL)['P5_45'].to_dataframe()\n",
    "            SLR_5_rcp45.index = SLR_5_rcp45.index.round('H')\n",
    "\n",
    "\n",
    "            MSLR_rcp85 = PtosObjtvo_MSL_nc.sel(point = point_selec_MSL)['m_ensemble85'].to_dataframe()\n",
    "            MSLR_rcp85.index = MSLR_rcp85.index.round('H')\n",
    "\n",
    "            SLR_95_rcp85   = PtosObjtvo_MSL_nc.sel(point = point_selec_MSL)['P95_85'].to_dataframe()\n",
    "            SLR_95_rcp85.index = SLR_95_rcp85.index.round('H')\n",
    "\n",
    "            SLR_5_rcp85   = PtosObjtvo_MSL_nc.sel(point = point_selec_MSL)['P5_85'].to_dataframe()\n",
    "            SLR_5_rcp85.index = SLR_5_rcp85.index.round('H')\n",
    "\n",
    "            AT = PtosObjtvo_MAT_nc.sel(point = point_selec_MAT)['tide'].to_dataframe()\n",
    "            AT.index = AT.index.round('H')\n",
    "\n",
    "            PMVE =AT.iloc[AT.values.argmax()-3:AT.values.argmax()+4]\n",
    "\n",
    "            setup_hist  = pd.DataFrame(index=Tp_his.index, columns=['setup'])\n",
    "            setup_rcp45 = pd.DataFrame(index=Tp_rcp_45.index, columns=['setup'])\n",
    "            setup_rcp85 = pd.DataFrame(index=Tp_rcp_85.index, columns=['setup'])\n",
    "\n",
    "            setup_hist.iloc[:,0]  = setup_fun (Tp_his.values,Hs_his.values*idoleaje,idplaya,slope,CStock)\n",
    "            setup_rcp45.iloc[:,0] = setup_fun (Tp_rcp_45.values,Hs_rcp_45.values*idoleaje,idplaya,slope,CStock)\n",
    "            setup_rcp85.iloc[:,0] = setup_fun (Tp_rcp_85.values,Hs_rcp_45.values*idoleaje,idplaya,slope,CStock)\n",
    "\n",
    "            ## C√°lculo de la cota de inundaci√≥n / TWL\n",
    "\n",
    "            Result_hist  = pd.concat((setup_hist,SS_his,AT),axis = 1).dropna()\n",
    "            Result_rcp45 = pd.concat((setup_rcp45,SS_rcp45,AT),axis=1).dropna()\n",
    "            Result_rcp85 = pd.concat((setup_rcp85,SS_rcp85,AT),axis=1).dropna()\n",
    "\n",
    "            TWL_hist  = Result_hist.iloc[:,0]+Result_hist.iloc[:,1]*idmarea+Result_hist.iloc[:,2]*idmarea+refNMMA\n",
    "            TWL_rcp45 = Result_rcp45.iloc[:,0]+Result_rcp45.iloc[:,1]*idmarea+Result_rcp45.iloc[:,2]*idmarea+refNMMA\n",
    "            TWL_rcp85 = Result_rcp85.iloc[:,0]+Result_rcp85.iloc[:,1]*idmarea+Result_rcp85.iloc[:,2]*idmarea+refNMMA\n",
    "\n",
    "            \n",
    "            TWL_rcp_45 = pd.concat((TWL_hist,TWL_rcp45.loc[:'2040'])).resample('A').max().dropna().astype(float)\n",
    "            TWL_rcp_85 = pd.concat((TWL_hist,TWL_rcp85.loc[:'2040'])).resample('A').max().dropna().astype(float)\n",
    "            \n",
    "            TWL_extrem_rcp_45 = Ajuste_GEV_KMA_Frechet(TWL_rcp_45,plot=False)\n",
    "            TWL_extrem_rcp_85 = Ajuste_GEV_KMA_Frechet(TWL_rcp_85,plot=False)\n",
    "            \n",
    "            MSLR_RCP45   = MSLR_rcp45.loc[:str(fin_year_period[t])].values[-1][0]\n",
    "            MSLR_RCP85   = MSLR_rcp85.loc[:str(fin_year_period[t])].values[-1][0]\n",
    "            SLR_5_RCP45  = SLR_5_rcp45.loc[:str(fin_year_period[t])].values[-1][0]\n",
    "            SLR_5_RCP85  = SLR_5_rcp85.loc[:str(fin_year_period[t])].values[-1][0]\n",
    "            SLR_95_RCP45 = SLR_95_rcp45.loc[:str(fin_year_period[t])].values[-1][0]\n",
    "            SLR_95_RCP85 = SLR_95_rcp85.loc[:str(fin_year_period[t])].values[-1][0]\n",
    "            \n",
    "            TWL_extrem_rcp_45_tab.iloc[i,:len(PeriodoRetorno)]  = (TWL_extrem_rcp_45.values).reshape(1,-1)\n",
    "            TWL_extrem_rcp_85_tab.iloc[i,:len(PeriodoRetorno)]  = (TWL_extrem_rcp_85.values).reshape(1,-1)\n",
    "            \n",
    "            \n",
    "            TWL_extrem_rcp_45_tab.iloc[i,len(PeriodoRetorno):]  = [MSLR_RCP45, SLR_5_RCP45, SLR_95_RCP45]\n",
    "            TWL_extrem_rcp_85_tab.iloc[i,len(PeriodoRetorno):]  = [MSLR_RCP85, SLR_5_RCP85, SLR_95_RCP85]\n",
    "            \n",
    "        \n",
    "            TWL_extrem_his       = Ajuste_GEV_KMA_Frechet(TWL_hist.resample('A').max().dropna().astype(float),plot=False)\n",
    "            TWL_extrem_hist_tab.iloc[i,:len(PeriodoRetorno)] = (TWL_extrem_his.values).reshape(1,-1)\n",
    "            \n",
    "        TWL_extrem_rcp_45_tab.to_csv(path_project+'sites/CC/'+'TWL_extrem_'+model+'_RCP45_'+str(fin_year_period[t])+'.csv')\n",
    "        TWL_extrem_rcp_85_tab.to_csv(path_project+'sites/CC/'+'TWL_extrem_'+model+'_RCP85_'+str(fin_year_period[t])+'.csv')\n",
    "        TWL_extrem_hist_tab.to_csv(path_project+'sites/CC/'+'TWL_extrem_'+model+'_his.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_files_extrems(path_inputs_dinamicas,model,path_project,table_point_carac,refNMMA,fin_year_period,cod_epsg):\n",
    "    \"\"\" La siguiente funci√≥n nos permite generar los ficheros de TWL para cada escenario de cambio clim√°tico.\n",
    "        A continuaci√≥n se explican cada uno de los par√°metros de entrada necesarios y los outputs generados\n",
    "        \n",
    "        Par√°metros:\n",
    "        ---------------------\n",
    "        path_inputs_dinamicas   : string. path donde se encuentran los netcdf de las din√°micas para cada uno de los puntos de estudio\n",
    "        model                   : string. Modelo de cambio clim√°tico que se desea analizar\n",
    "        path_project            : string. path donde se encuentra el proyecto de RFSM\n",
    "        table_point_carac       : pandas dataframe. Dataframe con las coordenadas y caracter√≠sticas de los puntos donde se van a asignar las din√°micas\n",
    "        refNMMA                 : float. Referencia nivel medio del mar\n",
    "        fin_year_period         : array. Fecha de fin de cada uno de los per√≠odos que se desean analizar\n",
    "        cod_epsg                : int. C√≥digo epsg del sistema de coordenadas utilizado en las coordendas de los puntos de estudio\n",
    "        \n",
    "        Salidas:\n",
    "        ---------------------\n",
    "        Ficheros csv para cada uno de modelos, escenarios y periodos.\n",
    "    \n",
    "    \"\"\"\n",
    "    PtosObjtvo_ROW_his_nc = xr.open_dataset(path_inputs_dinamicas+'PtosObjtvo_DIN_ROW_his.nc')\n",
    "    PtosObjtvo_MAT_nc = xr.open_dataset(path_inputs_dinamicas+'PtosObjtvo_MAT.nc')\n",
    "\n",
    "    PeriodoRetorno=[2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100,200,500,1000]\n",
    "    string_PR = [str(int) for int in PeriodoRetorno]\n",
    "    \n",
    "    print('Calculando TWL del per√≠odo hasta '+str(fin_year_period[t]))\n",
    "\n",
    "    TWL_extrem_hist_tab = pd.DataFrame(index=table_point_carac.index,columns=string_PR+['MSLR','SLR_5','SLR_95'])\n",
    "    TWL_extrem_hist_tab.loc[:,['MSLR','SLR_5','SLR_95']] = 0\n",
    "\n",
    "    for i in tqdm.tqdm(range(len(table_point_carac))):\n",
    "\n",
    "        x_0 = table_point_carac.iloc[i,0]\n",
    "        y_0 = table_point_carac.iloc[i,1]\n",
    "\n",
    "        inProj = Proj(init='epsg:'+str(cod_epsg))\n",
    "        outProj = Proj(init='epsg:4326')\n",
    "\n",
    "        x,y = transform(inProj,outProj,x_0,y_0)\n",
    "\n",
    "\n",
    "        idoleaje = table_point_carac.iloc[i,2]\n",
    "        idmarea = table_point_carac.iloc[i,3]\n",
    "        idplaya = table_point_carac.iloc[i,3]\n",
    "        slope = table_point_carac.iloc[i,4]\n",
    "        CStock = table_point_carac.iloc[i,5]\n",
    "\n",
    "        point_selec_his = PtosObjtvo_ROW_his_nc.point.data[np.sqrt((x-PtosObjtvo_ROW_his_nc.lon.data)**2+(y-PtosObjtvo_ROW_his_nc.lat.data)**2).argmin()]\n",
    "\n",
    "        point_selec_MAT = PtosObjtvo_MAT_nc.point.data[np.sqrt((x-PtosObjtvo_MAT_nc.lon.data)**2+(y-PtosObjtvo_MAT_nc.lat.data)**2).argmin()]\n",
    "\n",
    "\n",
    "\n",
    "        Hs_his = PtosObjtvo_ROW_his_nc.sel(point = point_selec_his)['hs'].to_dataframe()\n",
    "        Hs_his.index = Hs_his.index.round('H')\n",
    "        try:\n",
    "            Hs_his[Hs_his.hs<0]=0.001\n",
    "        except:\n",
    "            Hs_his = Hs_his\n",
    "\n",
    "        Tp_his = PtosObjtvo_ROW_his_nc.sel(point = point_selec_his)['tps'].to_dataframe()\n",
    "        Tp_his.index = Tp_his.index.round('H')\n",
    "        try:\n",
    "            Tp_his[Tp_his.tps<=0]=np.mean(Tp_his[Tp_his>0],axis=0)\n",
    "        except:\n",
    "            Tp_his = Tp_his\n",
    "\n",
    "        SS_his = PtosObjtvo_ROW_his_nc.sel(point = point_selec_his)['zeta'].to_dataframe()\n",
    "        SS_his.index = SS_his.index.round('H')\n",
    "\n",
    "\n",
    "        AT = PtosObjtvo_MAT_nc.sel(point = point_selec_MAT)['tide'].to_dataframe()\n",
    "        AT.index = AT.index.round('H')\n",
    "\n",
    "        PMVE =AT.iloc[AT.values.argmax()-3:AT.values.argmax()+4]\n",
    "\n",
    "        setup_hist  = pd.DataFrame(index=Tp_his.index, columns=['setup'])\n",
    "\n",
    "        setup_hist.iloc[:,0]  = setup_fun (Tp_his.values,Hs_his.values*idoleaje,idplaya,slope,CStock)\n",
    "\n",
    "        ## C√°lculo de la cota de inundaci√≥n / TWL\n",
    "\n",
    "        Result_hist  = pd.concat((setup_hist,SS_his,AT),axis = 1).dropna()\n",
    "\n",
    "        TWL_hist  = Result_hist.iloc[:,0]+Result_hist.iloc[:,1]*idmarea+Result_hist.iloc[:,2]*idmarea+refNMMA\n",
    "\n",
    "        TWL_extrem_his       = Ajuste_GEV_KMA_Frechet(TWL_hist.resample('A').max().dropna().astype(float),plot=False)\n",
    "        TWL_extrem_hist_tab.iloc[i,:len(PeriodoRetorno)] = (TWL_extrem_his.values).reshape(1,-1)\n",
    "            \n",
    "        TWL_extrem_hist_tab.to_csv(path_project+'sites/'+'TWL_extrem_'+model+'_his.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_files_extrems(path_inputs_dinamicas,path_project,table_point_carac,refNMMA,cod_epsg):\n",
    "    \"\"\" La siguiente funci√≥n nos permite generar los ficheros de TWL para el escenario ROW.\n",
    "        A continuaci√≥n se explican cada uno de los par√°metros de entrada necesarios y los outputs generados\n",
    "        \n",
    "        Par√°metros:\n",
    "        ---------------------\n",
    "        path_inputs_dinamicas   : string. path donde se encuentran los netcdf de las din√°micas para cada uno de los puntos de estudio\n",
    "        path_project            : string. path donde se encuentra el proyecto de RFSM\n",
    "        table_point_carac       : pandas dataframe. Dataframe con las coordenadas y caracter√≠sticas de los puntos donde se van a asignar las din√°micas\n",
    "        refNMMA                 : float. Referencia nivel medio del mar\n",
    "        cod_epsg                : int. C√≥digo epsg del sistema de coordenadas utilizado en las coordendas de los puntos de estudio    \n",
    "        \n",
    "        Salidas:\n",
    "        ---------------------\n",
    "        Ficheros csv para cada uno de modelos, escenarios y periodos.\n",
    "    \n",
    "    \"\"\"\n",
    "    PtosObjtvo_ROW_his_nc = xr.open_dataset(path_inputs_dinamicas+'PtosObjtvo_DIN_ROW_his.nc')\n",
    "    PtosObjtvo_MAT_nc = xr.open_dataset(path_inputs_dinamicas+'PtosObjtvo_MAT.nc')\n",
    "\n",
    "    PeriodoRetorno=[2, 3, 4, 5, 6, 7, 8, 9, 10, 20,25, 30, 40, 50, 60, 70, 80, 90, 100,200,500,1000]\n",
    "    string_PR = [str(int) for int in PeriodoRetorno]\n",
    "    \n",
    "    print('Calculando TWL')\n",
    "\n",
    "    TWL_extrem_hist_tab = pd.DataFrame(index=table_point_carac.index,columns=string_PR+['MSLR','SLR_5','SLR_95'])\n",
    "    TWL_extrem_hist_tab.loc[:,['MSLR','SLR_5','SLR_95']] = 0\n",
    "    \n",
    "    Params_extrem_his    = pd.DataFrame(index=table_point_carac.index,columns=['c','loc','scale'])\n",
    "\n",
    "    for i in tqdm.tqdm(range(len(table_point_carac))):\n",
    "\n",
    "        x_0 = table_point_carac.iloc[i,0]\n",
    "        y_0 = table_point_carac.iloc[i,1]\n",
    "\n",
    "        inProj = Proj(init='epsg:'+str(cod_epsg))\n",
    "        outProj = Proj(init='epsg:4326')\n",
    "\n",
    "        x,y = transform(inProj,outProj,x_0,y_0)\n",
    "\n",
    "\n",
    "        idoleaje = table_point_carac.iloc[i,2]\n",
    "        idmarea = table_point_carac.iloc[i,3]\n",
    "        idplaya = table_point_carac.iloc[i,3]\n",
    "        slope = table_point_carac.iloc[i,4]\n",
    "        CStock = table_point_carac.iloc[i,5]\n",
    "\n",
    "        point_selec_his = PtosObjtvo_ROW_his_nc.point.data[np.sqrt((x-PtosObjtvo_ROW_his_nc.lon.data)**2+(y-PtosObjtvo_ROW_his_nc.lat.data)**2).argmin()]\n",
    "\n",
    "        point_selec_MAT = PtosObjtvo_MAT_nc.point.data[np.sqrt((x-PtosObjtvo_MAT_nc.lon.data)**2+(y-PtosObjtvo_MAT_nc.lat.data)**2).argmin()]\n",
    "\n",
    "\n",
    "\n",
    "        Hs_his = PtosObjtvo_ROW_his_nc.sel(point = point_selec_his,drop=True)['hs'].to_dataframe()\n",
    "        Hs_his.index = Hs_his.index.round('H')\n",
    "        try:\n",
    "            Hs_his[Hs_his.hs<0]=0.001\n",
    "        except:\n",
    "            Hs_his = Hs_his\n",
    "\n",
    "        Tp_his = PtosObjtvo_ROW_his_nc.sel(point = point_selec_his,drop=True)['tps'].to_dataframe()\n",
    "        Tp_his.index = Tp_his.index.round('H')\n",
    "        try:\n",
    "            Tp_his[Tp_his.tps<=0]=np.mean(Tp_his[Tp_his>0],axis=0)\n",
    "        except:\n",
    "            Tp_his = Tp_his\n",
    "\n",
    "        SS_his = PtosObjtvo_ROW_his_nc.sel(point = point_selec_his,drop=True)['zeta'].to_dataframe()\n",
    "        SS_his.index = SS_his.index.round('H')\n",
    "\n",
    "\n",
    "        AT = PtosObjtvo_MAT_nc.sel(point = point_selec_MAT,drop=True)['tide'].to_dataframe()\n",
    "        AT.index = AT.index.round('H')\n",
    "\n",
    "        PMVE =AT.iloc[AT.values.argmax()-3:AT.values.argmax()+4]\n",
    "\n",
    "        setup_hist  = pd.DataFrame(index=Tp_his.index, columns=['setup'])\n",
    "\n",
    "        setup_hist.iloc[:,0]  = setup_fun (Tp_his.values,Hs_his.values*idoleaje,idplaya,slope,CStock)\n",
    "\n",
    "        ## C√°lculo de la cota de inundaci√≥n / TWL\n",
    "\n",
    "        Result_hist  = pd.concat((setup_hist,SS_his,AT),axis = 1).dropna()\n",
    "\n",
    "        TWL_hist  = Result_hist.iloc[:,0]+Result_hist.iloc[:,1]*idmarea+Result_hist.iloc[:,2]*idmarea+refNMMA\n",
    "        \n",
    "\n",
    "        TWL_hist  = Result_hist.iloc[:,0]+Result_hist.iloc[:,1]*idmarea+Result_hist.iloc[:,2]*idmarea+refNMMA\n",
    "           \n",
    "        TWL_extrem_his = Ajuste_GEV_KMA_Frechet(TWL_hist.resample('A').max().dropna().astype(float),path_project,save_plot=False,name_fig=None)[0]\n",
    "              \n",
    "        TWL_extrem_hist_tab.iloc[i,:len(PeriodoRetorno)]   = TWL_extrem_his.values.reshape(1,-1)\n",
    "        \n",
    "        Params_extrem_his.iloc[i,:]     = Ajuste_GEV_KMA_Frechet(TWL_hist.resample('A').max().dropna().astype(float),path_project,save_plot=True,name_fig='Params_extrem_'+'_ROW_'+'_POINT_'+str(i))[1:]\n",
    "              \n",
    "    TWL_extrem_hist_tab.to_csv(path_project+'sites/'+'TWL_extrem_ROW.csv')\n",
    "    Params_extrem_his.to_csv(path_project+'sites/'+'Params_extrem_ROW.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tusrBCFlowLevel(table_points,file_TWL,temporal,path_project,TestDesc,Table_impact_zone,\n",
    "                     izcoast,BCSetID,BCTypeID_COAST,return_period,SLR,\n",
    "                    raw_q=True, point_X_river = None ,point_Y_river = None ,hidrograma=None):\n",
    "    \n",
    "    \"\"\"La siguiente funci√≥n nos permite generar los ficheros de condici√≥n de contorno de RFSM.\n",
    "    \n",
    "       Par√°metros:\n",
    "       ---------------------\n",
    "       table_points       : pandas dataframe. Dataframe con las coordenadas y caracter√≠sticas de los puntos donde asignaron las din√°micas\n",
    "       file_TWL           : pandas dataframe. Dataframe que contiene los puntos donde se extraen los per√≠odos de retrono\n",
    "       temporal           : pandas dataframe. Dataframe que contiene el temporal de referencia.\n",
    "       path_project       : string. path donde se encuentra el proyecto de RFSM\n",
    "       TestDesc           : string. Nombre de la simulaci√≥n\n",
    "       Table_impact_zone  : pandas dataframe.  Dataframe con el conjunto de impact zones\n",
    "       izcoast            : pandas dataframe.  Dataframe con el conjunto de impact zones donde se asigna condici√≥n de contorno costera\n",
    "       BCSetID            : int. Identificador de la simulaci√≥n\n",
    "       BCTypeID_COAST     : int. Tipo de condici√≥n de contorno # 1 overtopping; # 2 level;\n",
    "       return_period      : int. Per√≠odo de retorno estudiado\n",
    "       SLR                : float: Sea Level Rise\n",
    "       raw_q              : True or False: Si existe un punto donde se va introducir un caudal en un cauce poner en True\n",
    "       point_X_river      : float. Si existe un punto donde se va introducir un caudal en un cauce a√±adir \n",
    "       point_Y_river      : float. Si existe un punto donde se va introducir un caudal en un cauce poner en True\n",
    "       hidrograma         : array. Si existe un punto donde se va introducir un caudal en un cauce a√±adir hidrograma \n",
    "       \n",
    "        Salidas:\n",
    "        ---------------------\n",
    "        Fichero tusrBCFlowLevel necesario para la ejecuci√≥n de RFSM.\n",
    "       \n",
    "       \n",
    "       \n",
    "        \"\"\"\n",
    "    \n",
    "    Table_impact_zone_edit =Table_impact_zone.copy()\n",
    "    Table_impact_zone_edit.loc[:,'BCTypeID'] = 0\n",
    "    \n",
    "    cI = temporal\n",
    "    cI = [cI[0]*1/10,cI[0]*3/10,cI[0]*5/10,cI[0]*7/10,cI,cI[-1]*7/10,cI[-1]*5/10,cI[-1]*3/10,cI[-1]*1/10]\n",
    "   \n",
    "    n_periods = len(cI)\n",
    "    \n",
    "    Table_impact_zone_edit.loc[izcoast.index,'BCTypeID'] = BCTypeID_COAST\n",
    "    \n",
    "    if raw_q==True:\n",
    "        \n",
    "        dist = np.sqrt((point_X_river-Table_impact_zone_edit.iloc[:,2])**2+(point_Y_river-Table_impact_zone_edit.iloc[:,3])**2)\n",
    "        point_select=dist.idxmin()\n",
    "        \n",
    "        Table_impact_zone_edit.loc[point_select,'BCTypeID'] = 10\n",
    "        \n",
    "    Results_TWL = pd.DataFrame(index=np.arange(0,sum(Table_impact_zone_edit.BCTypeID.values>0)*n_periods),columns=['BCSetID', 'BCTypeID', 'IZID', 'Time', 'BCValue'])\n",
    "    \n",
    "    Table_impact_zone_edit_2=Table_impact_zone_edit[Table_impact_zone_edit.BCTypeID!=0].copy()\n",
    "    \n",
    "    it=0\n",
    "    for iDZ in tqdm.tqdm(range(len(Table_impact_zone_edit_2))):\n",
    "        if (Table_impact_zone_edit_2['BCTypeID'].iloc[iDZ]==2) or (Table_impact_zone_edit_2['BCTypeID'].iloc[iDZ]==1):\n",
    "\n",
    "            x_pointIZID = Table_impact_zone_edit_2[' MidX'].values[iDZ]\n",
    "            y_pointIZID = Table_impact_zone_edit_2[' MidY'].values[iDZ]\n",
    "            IZID = Table_impact_zone_edit_2.index[iDZ]\n",
    "\n",
    "            dist = np.sqrt((x_pointIZID-table_points.iloc[:,0])**2+(y_pointIZID-table_points.iloc[:,1])**2)\n",
    "            point_select=dist.idxmin()\n",
    "\n",
    "            \n",
    "            TWL=table_points.loc[return_period,table_points.iloc[point_select]]\n",
    "            \n",
    "            cITr = cI/max(cI)*TWL\n",
    "            pos1= np.where(cITr == np.max(cITr))[0]\n",
    "\n",
    "            cITr[pos1]= cITr[pos1] + SLR\n",
    "            \n",
    "            if BCTypeID_COAST ==1:\n",
    "                cITr = cITr*izcoast.nCells[IZID]*cellsize\n",
    "            else:\n",
    "                cITr = cITr-izcoast.minH[IZID]\n",
    "                cITr[cITr<0]=0\n",
    "                \n",
    "            \n",
    "\n",
    "            Results_TWL.iloc[it:it+n_periods,0] = BCSetID\n",
    "            Results_TWL.iloc[it:it+n_periods,1] = BCTypeID_COAST\n",
    "            Results_TWL.iloc[it:it+n_periods,2] = IZID\n",
    "            Results_TWL.iloc[it:it+n_periods,3] = np.linspace(0,3600*len(cITr),len(cITr))\n",
    "            Results_TWL.iloc[it:it+n_periods,4] = cITr\n",
    "\n",
    "            it=it+n_periods\n",
    "\n",
    "            del W, MM, MA, Hs, setup, TWL\n",
    "\n",
    "        elif Table_impact_zone_edit_2['BCTypeID'].iloc[iDZ]==10:\n",
    "            print('R√≠o')\n",
    "            Results_TWL.iloc[it:it+n_periods,0] = BCSetID\n",
    "            Results_TWL.iloc[it:it+n_periods,1] = 1\n",
    "            Results_TWL.iloc[it:it+n_periods,2] = IZID\n",
    "            Results_TWL.iloc[it:it+n_periods,3] = np.linspace(0,3600*len(hidrograma),len(hidrograma))\n",
    "            Results_TWL.iloc[it:it+n_periods,4] = hidrograma\n",
    "\n",
    "            it=it+n_periods\n",
    "            \n",
    "    Results_TWL.to_csv(path_project+'tests/'+TestDesc+'/Input_User/tusrBCFlowLevel.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_netcf_Dinamicas_DOW(path_files,path_output,model,scenario):\n",
    "    directory = list() \n",
    "    for file in os.listdir(path_files):\n",
    "        if file.startswith(\"Punto\"):\n",
    "            directory.append(file)\n",
    "    names_point = list()\n",
    "    lon = list()\n",
    "    lat = list()\n",
    "    \n",
    "    \n",
    "    \n",
    "    for d, dd in enumerate(directory):\n",
    "        pos_ = [*find_all(dd, '[')]\n",
    "        pos_r = [*find_all(dd, ']')]\n",
    "        \n",
    "        names_point.append(dd[:pos_[0]-1])\n",
    "        lon.append(float(dd[pos_[0]+1:pos_r[0]]))\n",
    "        lat.append(float(dd[pos_[1]+1:pos_r[1]]))  \n",
    "        \n",
    "    for i,ii in enumerate(tqdm.tqdm(directory)):\n",
    "        if model == 'DOW2' and scenario == 'his':\n",
    "            path_file_ = path_files+directory[i]+'/'+directory[i]+'_'+'DOW2'+'.mat'\n",
    "        else:\n",
    "            path_file_ = path_files+directory[i]+'/'+directory[i]+'_'+model+'_'+scenario+'.mat'\n",
    "        \n",
    "        if i ==0:\n",
    "            mat    = scipy.io.loadmat(path_file_)\n",
    "            time   = mat['time'].flatten()\n",
    "            hs_o   = mat['hs'].reshape(1,-1)\n",
    "            tps_o  = mat['tps'].reshape(1,-1)\n",
    "            dir_o  = mat['dir'].reshape(1,-1)\n",
    "            zeta_o = mat['zeta'].reshape(1,-1)\n",
    "            tm02_o = mat['tm02'].reshape(1,-1)\n",
    "            bat_o = mat['bat']\n",
    "        else:\n",
    "            try:\n",
    "                mat = scipy.io.loadmat(path_file_)\n",
    "            except:\n",
    "                print('Error en el fichero: '+ path_file_)\n",
    "                continue\n",
    "            hs_o   = np.concatenate((hs_o, mat['hs'].reshape(1,-1)), axis=0)\n",
    "            tps_o  = np.concatenate((tps_o, mat['tps'].reshape(1,-1)), axis=0)\n",
    "            dir_o  = np.concatenate((dir_o, mat['dir'].reshape(1,-1)), axis=0)\n",
    "            zeta_o = np.concatenate((zeta_o, mat['zeta'].reshape(1,-1)), axis=0)\n",
    "            tm02_o = np.concatenate((tm02_o, mat['tm02'].reshape(1,-1)), axis=0)\n",
    "            bat_o = np.concatenate((bat_o, mat['bat']), axis=0)\n",
    "        \n",
    "    time_py = matDatenum2PYDatetime(time,unitTime = 'D')[0]\n",
    "    \n",
    "    nc = Dataset(path_output+'PtosObjtvo_DIN_'+model+'_'+scenario+'.nc', 'w', format='NETCDF4')\n",
    "    # Global Attributes \n",
    "    nc.description= 'Contiene las din√°micas del modelo '+model+' en el escenario '+scenario  \n",
    "    # nc dimensions\n",
    "    nc.createDimension('lon',  len(lon))\n",
    "    nc.createDimension('lat',  len(lat))\n",
    "    nc.createDimension('time',len(time))\n",
    "    nc.createDimension('point',len(names_point))\n",
    "    # crear variables\n",
    "    xx_nc=nc.createVariable('lon','float32', ('lon'))\n",
    "    yy_nc=nc.createVariable('lat','float32', ('lat'))\n",
    "    time_nc=nc.createVariable('time','float32',('time'))\n",
    "    point_nc = nc.createVariable('point','int',('point'))\n",
    "    hs_nc=nc.createVariable('hs','float32', ('time','point'))\n",
    "    tps_nc=nc.createVariable('tps','float32', ('time','point'))\n",
    "    dir_nc=nc.createVariable('dir','float32', ('time','point'))\n",
    "    zeta_nc=nc.createVariable('zeta','float32', ('time','point'))\n",
    "    tm02_nc=nc.createVariable('tm02','float32', ('time','point'))\n",
    "    bat_nc = nc.createVariable('bat','float32',('point'))\n",
    "    #units\n",
    "    xx_nc.units = 'degrees_east'\n",
    "    yy_nc.units = 'degrees_north'\n",
    "    time_nc.units='days since '+str(time_py[0].year)+'-01-01'\n",
    "    hs_nc.units='m'\n",
    "    tps_nc.units='s'\n",
    "    dir_nc.units='¬∫'\n",
    "    zeta_nc.units='¬∫'\n",
    "    tm02_nc.units='s'\n",
    "    point_nc.units = ''\n",
    "    bat_nc.units = 'm'\n",
    "    #long_name\n",
    "    xx_nc.long_name = 'longitude coordinate'\n",
    "    yy_nc.long_name = 'latitud coordinate'\n",
    "    time_nc.long_name='dias del a√±o'\n",
    "    hs_nc.long_name='Altura de ola'\n",
    "    tps_nc.long_name='Per√≠odo de pico suavizado'\n",
    "    dir_nc.long_name='Direcci√≥n'\n",
    "    zeta_nc.long_name='Marea meteorol√≥gica'\n",
    "    tm02_nc.long_name='Periodo medio'\n",
    "    point_nc.long_name = 'Puntos de estudio'\n",
    "    bat_nc.long_name = 'Profundidad'\n",
    "    # calendar\n",
    "    time_nc.calendar = 'standard'\n",
    "    # rellenar variables\n",
    "    point_nc[:]=np.arange(1,len(names_point)+1)\n",
    "    xx_nc[:]=lon\n",
    "    yy_nc[:]=lat\n",
    "    time_nc[:]=date2num(time_py.to_pydatetime(), units='days since '+str(time_py[0].year)+'-01-01', calendar='standard')\n",
    "    hs_nc[:]=hs_o[:,:].T\n",
    "    tps_nc[:]=tps_o[:,:].T\n",
    "    dir_nc[:]=dir_o[:,:].T\n",
    "    zeta_nc[:] = zeta_o[:,:].T\n",
    "    tm02_nc[:]=tm02_o[:,:].T\n",
    "    bat_nc[:]=bat_o[:].T\n",
    "    nc.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
